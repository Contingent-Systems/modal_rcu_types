\section{Related Work}
\label{sec:relatedwork}
Related work for correctness of code involving RCU memory management includes relevant work in concurrent program logics, model checking, and type systems.
\subsection{Overview on Existing Approaches}
%(\textit{\textbf{Program Logic}}) -
\mypar{Modeling RCU}
Alglave et al.~\cite{Alglave:2018:FSC:3173162.3177156} propose a memory model to be assumed by the platform-independent parts of the Linux kernel, regardless of the underlying hardware's memory model.
As part of this, they give the first formalization of what it means for an RCU implementation to be correct (previously this was difficult to state, as the guarantees in principle could vary by underlying CPU architecture). Essentially, that reader critical sections do not span grace periods.  They prove by hand that the Linux kernel RCU implementation~\cite{DBLP:conf/cav/AlglaveKT13,abssem} satisfies this property. 
According to their definition, our model in Section \ref{sec:semantics} is a valid RCU implementation (assuming sequential consistency).
To the best of our knowledge, ours is the first abstract \emph{operational} model for a Linux kernel-style RCU implementation --- others are implementation-specific~\cite{Mandrykin:2016:TDV:3001219.3001297} or axiomatic like Alglave et al.'s. Tassarotti et al. models a well-known way of implementing RCU synchronization without hurting readers' performance, \textsf{Quiescent State Based Reclamation}(QSBR)~\cite{urcu_ieee} where synchronization in between the writer thread and reader threads provided via per-thread counters. 

\mypar{Program Logics} Fu et al.~\cite{shao_temp} extend Rely-Guarantee/Separation-Logic ~\cite{vafeiadis07,Feng:2007:RCS:1762174.1762193,Feng:2009:LRR:1480881.1480922} with the \textit{past-tense} temporal operator to eliminate the need for using the history variable and lift the standard separation conjuction to assert over on execution histories instead of state to capture the high level intuitive specification of Michael's non-blocking stack~\cite{Michael:2004:HPS:987524.987595}. Gotsman et al.~\cite{Gotsman:2013:VCM:2450268.2450289} take a similar approach and present a formalization of memory management using grace periods in an extension to separation logic, specifically an extension of Vafeiadis and Parkinson's \textsf{RGSep}~\cite{vafeiadis07}. Gotsman et al. take assertions from temporal logic to capture the essence of relaxed memory reclamation algorithms and have simpler proofs than Fu et al. have~\cite{shao_temp} for Micheal's non-blocking stack~\cite{Michael:2004:HPS:987524.987595} implementation under a sequentially consistent memory model. Mandrykin et al.~\cite{Mandrykin:2016:TDV:3001219.3001297} use \textsf{VCC}~\cite{Cohen:2009:VPS:1616077.1616080} to verify an implementation of RCU primitives using specifications relating to a specific implementation, and do not verify client code.

\mypar{Weak Memory Models} Tassarotti et al.~\cite{verrcu} uses a protocol based program logic based on separation and ghost variables called \textsf{GPS}~\cite{Turon:2014:GNW:2660193.2660243} to verify user-level \textsf{RCU} singly linked list under \emph{release-acquire} semantics, which is a weaker memory model than sequential-consistency. They enforce the safe synchronization protocol in between the readers and the writer thread through \textit{release-writes} and \textit{acquire-reads} of the counters as a part of the QSRB model. We do capture all the guarantees from these \textit{release-acquire} orderings in our model via \textit{logical observations} -- e.g. (\textsf{iterator} $tid$, \textsf{unlinked} and \textsf{freeable}) -- the writer thread makes on the heap. Based on our comparative understanding taking Tassarotti's work as a reference, although we do not show it formally within the scope of this paper, we do not see any fundamental reason for not having our model to work under \textit{release-acquire} semantics.

\mypar{Separation of Concerns for Client Verification}: We think that instantiating a basis logic requires an effort on providing clean separation between client verification and full functional correctness of a model. \textit{This effort is subtle and important}. Meyer et al. ~\cite{myr} presents a methodology to separate \textit{linearasibility} proofs for Michael\&Scott's queue~\cite{Michael:1996:SFP:248052.248106} and DGLM~\cite{Doherty:2004:DSB:1007912.1007945} from memory reclamation model via establishing an over approximation for the \textit{epoch-based} and \textit{hazard-pointers} reclamation model. We hope our generic abstractions for linked-data structures inspire them when they integrate linked-data structure abstractions(e.g. linked-list) to their methodology. Regarding specifying client's action, Tassarotti et al. provide \textit{abstract-predicates} -- e.g. WriterSafe -- which might not be so reusable for an arbitrary RCU client -- e.g. binary search tree -- as they include linked list specific logical constructions together with the constructions for QSRB model. On the other hand, we manage to keep our types for client specification not only relatively simple but also reusable for different clients (e.g. a linked list in Appendix \ref{appendix:bag_paul} and a binary search tree in Appendix \ref{appendix:bst_del} via careful instantiation of Views framework: logical state including thread's observations, global memory invariants in Appendix \ref{sec:lemmas} and the denotations of our types in Figure \ref{fig:denotingtypeenviroment} Section \ref{sec:soundness}. 
%The writer thread \textit{release-writes} to its own counter to start synchronization(corresponds to setting the bounding threads to be same with the set of readers) and by doing so it publishes the fact that the updated heap node is no more reachable for the new coming reader threads. When a reader thread \textit{acquire-reads} the updated writer counter, it \textit{release-writes} the value to its own counter to announce that it is done with the heap node and is now \textit{quiescent}(corresponds to removing the reader's identifier both from the readers' set and bounding threads' set when exiting read-side critical section). After updating its counter, the writer thread repeatedly \textit{acquire-reads} the readers' counter to check whether they are all \textit{quiescent}(corresponds to the empty set of bounding threads). If so, then it is safe for the writer thread to reclaim the unreachable old heap node. We do capture all of these \textit{release-acquire} orderings based on the \textit{logical observations}(\textsf{iterator} $tid$, \textsf{unlinked} and \textsf{freeable}) of the writer thread on the heap and its importance is twofold:
%\begin{itemize}
%\item  Although we do not show it formally within the scope of this paper, we do not see any fundamental reason for having our model to work under \textit{release-acquire} semantics.
%\item Tassarotti et al. provide \textit{abstract-predicates} -- e.g. WriterSafe -- (which mainly corresponds to our global memory invariants in Appendix \ref{sec:lemmas} and the denotations of our types in Figure \ref{fig:denotingtypeenviroment} Section \ref{sec:soundness}) to be asserted and discharged for each of the RCU client actions and these abstract predicates might not be so reusable for another RCU client -- e.g. binary search tree -- as they include linked list specific logical constructions. Regarding memory safety of RCU clients, it is important to emphasise that we use the same types for different clients(e.g. a linked list in Appendix \ref{appendix:bag_paul} and a binary search tree in Appendix \ref{appendix:bst_del}) without having to prove the RCU properties (e.g. unreachable nodes, proper orderings etc.) separately for each different RCU client: since we introduce the logical observation and memory safety properties within the \textit{meta-theory}(logical RCU state, global memory invariants and the denotations of the types) and prove all of the RCU properties as a part of the soundness proof just for once.
%\end{itemize}

\mypar{Realizing Our Abstract RCU Model} Efficient implementations minimizes the cost of the read-side critical section operations: entering/exiting to the read-side critical section. Typically, implementations are structured so each reader thread (or CPU) maintains its own \emph{fragment} of the shared global state, which is only updated by that thread, but is read by the write-side primitives. For example, Tassarotti et al.~\cite{verrcu} model the readers' counters as an array of counters where the content of each cell corresponds to the counter of a specific reader thread in QSRB model. On the other hand, a direct implementation of our semantics would yield unacceptable performance, since both entering(\lstinline|ReadBegin|) and exiting(\lstinline|ReadEnd|) modify shared data structures for the \textit{bounding-threads} and \textit{readers} sets. A slight variation on our semantics would use a bounding set  that tracked such a snapshot of counts, and a vector of per-thread counts in place of the reader set. Blocking grace period completion until the snapshot was strictly older than all current reader counts would be more clearly equivalent to these implementations. Our current semantics are simpler than this alternative, while also equivalent.However, we know that if we had this slight variation in the implementation for the \lstinline|ReadBegin| and \lstinline|ReadEnd| then all actions(traverse and read the node value) from a reader thread would \textit{reduce} to an \textit{atomic} read of a data value(logical atomicity of readers' actions). Since we do not provide the careful implementation for the the \lstinline|ReadBegin| and \lstinline|ReadEnd| we cannot provide the \textit{atomicity} proof as well.
%(\textit{\textbf{RCU Model and Model Checking}}) - %Alglave et al. gives first semantics for the Linux kernel's implementation of \textsf{RCU}~\cite{abssem,Alglave:2018:FSC:3173162.3177156,DBLP:conf/cav/AlglaveKT13}. It captures details(behaviours on memory models etc.) of \textsf{RCU} implementation in Linux Kernel so it is much detailed and close to real implementation than our semantics is. However, our semantics abstracts the one Alglave et al. presents without loosing the \textit{fundamental law of} \textsf{RCU}  ~\cite{Alglave:2018:FSC:3173162.3177156} against which we show that our type system enforces correct usage of \textsf{RCU} API to guarantee memory safety(proper reclamation) and properties like \textit{acyclicity} for data structures implemented with using the API soundly. 

\mypar{Model Checking}
Desnoyers et al. propose a virtual architecture to model out of order memory accesses and instruction scheduling~\cite{Desnoyers:2013:MSM:2506164.2506174} and use the \textsf{SPIN} model checker to verify a user-mode implementation of RCU~\cite{urcu_ieee}. This method requires manual translation from C to SPIN modelling language.
Liang et al. presents an approach to verify the \emph{grace period} guarantee of \textsf{Tree RCU} in Linux kernel~\cite{LiangMKM16}. \textsf{Tree RCU} is an hieararchical \textsf{RCU} model which is a remedy to contention of writer threads in the single global lock model. 
Similarly, Kokologiannakis et al.~\cite{Kokologiannakis:2017:SMC:3092282.3092287} use a stateless model checker for testing the core of \textsf{Tree RCU}.
Liang's approach has limited support for lists and callback handling which are important when we consider the correctness for writer primitives which are based on callback handling. Kokologiannakis's approach overcomes all these limitations and shows considerable performance when compared with Liang's approach using \textsf{CBMC}. 
%Our method do not consider optimized \textsf{RCU} implementation such as \textsf{Tree RCU} as we focus on enforcing correct usages of \textsf{RCU} primitives instead of giving formal semantics to optimized efficient \textsf{RCU} implementation.
Both focus on validating a particular RCU implementation, whereas we focus on verifying memory safety of clients independent of implementation.
  
\mypar{Type Systems}
Howard et al.~\cite{Howard:2011:RES:2001252.2001267} enhance \textsf{STM} in Haskell to a technique called \textit{Relativistic Programming} which aims low overhead linearly scalable concurrent threads. Unlike our system which types binary search tree in \textsf{RCU} setting, they claim  handling trees (look-up followed by update) as a future work.
A follow up paper from Cooper et al.~\cite{Cooper2015RelativisticPI} presents a \textsf{Haskell} library called \emph{Monadic RP}, for relativistic programming. Similar to our approach, Monadic RP provides types and relativistic programming constructs for write/read critical sections which enforce correct usage of relativistic programming pattern. 
They also have only checked a linked list.
Thus our work is the first type system for ensuring correct use of RCU primitives that is known to handle more complex structures than linked lists.
%\subsection{More on Efficiency in Real RCU Implementations}
%\label{sec:effici}
%\iso{I am no sure this part should be in the ESOP version.}
%Our simple global lock semantics for write critical sections has so many drawbacks in terms limiting the scalability and performance. The motivation of \textsf{RCU} is having very cheap reader critical sections but the number of reader theards can be a lot and this can be a problem. Although readers' performance are not effected badly, writer thread must show the grace period to all of these \emph{active/pre-existsting} readers in such a way that it must \emph{defer} the reclamation phase blocking (or in some implementations registering callback to be invoked after grace period) until all active readers are done with their jobs. Acquiring a global lock during each grace period severly affects scalibility and performance. To overcome this problem, a \emph{tree based} hieararchical mechanism is implemented to handle each thread's (CPU's) \emph{quiescent-state} information and \emph{grace-period}. In Tree RCU, the data strcuture is used in such a way that it records each CPU's quiescent states. The \textsf{rcu} node tree propagates these states up to the root, and then propagates grace-period information down to the leaves. Quiescent-state information does not propagate upwards from a given node until a quiescent state has been reported by each CPU covered by the subtree rooted at that node. This propagation scheme dramatically reduces the lock contention experienced by the upper levels of the tree ~\cite{LiangMKM16}
%
%Real implementations, of course, must also tolerate the weak memory model of whatever processor they run on, leading them to use. For example, the primitive to dereference a memory location shown by a pointer and the primitive to update the memory location shown by a pointer contain architecture-specific memory barrier instructions and compiler directives to enforce correct ordering. Both primitives reduce to simple assignment statements on sequentially consistent systems. Dereferencing is volatile access except on DEC Alpha, which also requires a memory barrier \todo{CITE}.
%
%The Linux implementation of the communication in between reader thread and writer thread is based on waiting for context switches. The implementation uses calls \lstinline|SyncStart| and returns back from \lstinline|SyncStop| after all CPUs have passed through at least one context switch. The synchronous version of the primitive to wait reader threads is \textsf{synchronize\_rcu}. For performance reasons, the Linux implementation has also asynchronous version of this primitive named \textsf{call\_rcu}. Detecting context switches requires maintaining state shared between CPUs. A CPU must update state, which other CPUs read, that indicate it executed a context switch ~\cite{Mckenney_rcuusage}.
